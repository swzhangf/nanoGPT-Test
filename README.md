# ðŸ§  NanoGPT Deployment & Smoke Test

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0%2B-orange)
![Status](https://img.shields.io/badge/Status-Operational-green)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

## ðŸ“– Introduction

This repository is a lightweight deployment and verification implementation based on [Andrej Karpathy's nanoGPT](https://github.com/karpathy/nanoGPT).

The primary goal of this project is to demonstrate a **complete end-to-end LLM lifecycle**â€”from data generation to model training and inferenceâ€”verified within a minimal compute environment (e.g., Google Colab T4 or local CPU/GPU).

We utilize a synthetic **"Tick Tock" pattern dataset** (or arithmetic logic) to conduct a "Smoke Test," ensuring that the model architecture, optimizer, and training loop are functioning correctly before scaling up to larger datasets like OpenWebText.

## ðŸš€ Features

- **Automated Data Pipeline**: Scripts to generate synthetic training data instantly.
- **Minimalist Configuration**: A tuned `smoke_test.py` config optimized for speed (trains in <30 seconds).
- **Deployment Ready**: Verified on Cloud (Colab) and Local environments.
- **Inference Verification**: Includes scripts to validate if the model has "learned" the pattern.

## ðŸ“‚ Project Structure

```text
nanoGPT/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ smoke_test.py      # <--- Custom config for rapid testing
â”‚   â””â”€â”€ train_shakespeare.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ smoke_test/        # Generated binary data (excluded from git)
â”œâ”€â”€ model.py               # GPT Model Definition
â”œâ”€â”€ train.py               # Training Script
â”œâ”€â”€ sample.py              # Inference/Sampling Script
â”œâ”€â”€ test_deploy.py         # Unit tests for environment checks
â””â”€â”€ README.md